{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression\n",
    "from sklearn.preprocessing import power_transform, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "from paretoset import paretoset\n",
    "from lifelines import WeibullAFTFitter, LogNormalAFTFitter, LogLogisticAFTFitter\n",
    "\n",
    "\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stage</th>\n",
       "      <th>attack</th>\n",
       "      <th>data</th>\n",
       "      <th>files</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>model</th>\n",
       "      <th>name</th>\n",
       "      <th>scorers</th>\n",
       "      <th>train_time</th>\n",
       "      <th>train_time_per_sample</th>\n",
       "      <th>...</th>\n",
       "      <th>model_layers</th>\n",
       "      <th>def_param</th>\n",
       "      <th>def_value</th>\n",
       "      <th>atk_param</th>\n",
       "      <th>atk_value</th>\n",
       "      <th>failure_rate</th>\n",
       "      <th>adv_failure_rate</th>\n",
       "      <th>training_time_per_failure</th>\n",
       "      <th>training_time_per_adv_failure</th>\n",
       "      <th>adv_training_time_per_failure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>attack</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>0009cf1504e3689e79934f78fcb00c7c</td>\n",
       "      <td>206.672264</td>\n",
       "      <td>0.003691</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>cutoff</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>eps</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>2.766349e+05</td>\n",
       "      <td>22947.190553</td>\n",
       "      <td>1.334096e-08</td>\n",
       "      <td>1.608291e-07</td>\n",
       "      <td>1.608291e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>attack</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>0022118d46ac791faba90c6f907516f0</td>\n",
       "      <td>203.195971</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps</td>\n",
       "      <td>0.123905</td>\n",
       "      <td>1.435355e+06</td>\n",
       "      <td>147157.749244</td>\n",
       "      <td>2.527946e-09</td>\n",
       "      <td>2.465721e-08</td>\n",
       "      <td>2.465721e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>attack</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>0036b069268b81ebc05519c3372608b9</td>\n",
       "      <td>46.047791</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb_grads</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.608925e+06</td>\n",
       "      <td>6524.344491</td>\n",
       "      <td>1.244199e-10</td>\n",
       "      <td>1.260329e-07</td>\n",
       "      <td>1.260329e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>attack</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>0059d34a86c5a8e25c3bb06da1cd6555</td>\n",
       "      <td>25.424851</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>nb_grads</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.488474e+04</td>\n",
       "      <td>10296.684193</td>\n",
       "      <td>4.784913e-09</td>\n",
       "      <td>4.409334e-08</td>\n",
       "      <td>4.409334e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attack</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>00603349e13a42bef3170206db60dea6</td>\n",
       "      <td>207.587490</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>cutoff</td>\n",
       "      <td>0.224719</td>\n",
       "      <td>max_iter</td>\n",
       "      <td>0.210526</td>\n",
       "      <td>3.184056e+04</td>\n",
       "      <td>73.692387</td>\n",
       "      <td>1.164213e-07</td>\n",
       "      <td>5.030261e-05</td>\n",
       "      <td>5.030261e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 196 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    stage                            attack                              data  \\\n",
       "0  attack  0009cf1504e3689e79934f78fcb00c7c  0009cf1504e3689e79934f78fcb00c7c   \n",
       "5  attack  0022118d46ac791faba90c6f907516f0  0022118d46ac791faba90c6f907516f0   \n",
       "6  attack  0036b069268b81ebc05519c3372608b9  0036b069268b81ebc05519c3372608b9   \n",
       "8  attack  0059d34a86c5a8e25c3bb06da1cd6555  0059d34a86c5a8e25c3bb06da1cd6555   \n",
       "9  attack  00603349e13a42bef3170206db60dea6  00603349e13a42bef3170206db60dea6   \n",
       "\n",
       "                              files                            kwargs  \\\n",
       "0  0009cf1504e3689e79934f78fcb00c7c  0009cf1504e3689e79934f78fcb00c7c   \n",
       "5  0022118d46ac791faba90c6f907516f0  0022118d46ac791faba90c6f907516f0   \n",
       "6  0036b069268b81ebc05519c3372608b9  0036b069268b81ebc05519c3372608b9   \n",
       "8  0059d34a86c5a8e25c3bb06da1cd6555  0059d34a86c5a8e25c3bb06da1cd6555   \n",
       "9  00603349e13a42bef3170206db60dea6  00603349e13a42bef3170206db60dea6   \n",
       "\n",
       "                              model                              name  \\\n",
       "0  0009cf1504e3689e79934f78fcb00c7c  0009cf1504e3689e79934f78fcb00c7c   \n",
       "5  0022118d46ac791faba90c6f907516f0  0022118d46ac791faba90c6f907516f0   \n",
       "6  0036b069268b81ebc05519c3372608b9  0036b069268b81ebc05519c3372608b9   \n",
       "8  0059d34a86c5a8e25c3bb06da1cd6555  0059d34a86c5a8e25c3bb06da1cd6555   \n",
       "9  00603349e13a42bef3170206db60dea6  00603349e13a42bef3170206db60dea6   \n",
       "\n",
       "                            scorers  train_time  train_time_per_sample  ...  \\\n",
       "0  0009cf1504e3689e79934f78fcb00c7c  206.672264               0.003691  ...   \n",
       "5  0022118d46ac791faba90c6f907516f0  203.195971               0.003628  ...   \n",
       "6  0036b069268b81ebc05519c3372608b9   46.047791               0.000822  ...   \n",
       "8  0059d34a86c5a8e25c3bb06da1cd6555   25.424851               0.000454  ...   \n",
       "9  00603349e13a42bef3170206db60dea6  207.587490               0.003707  ...   \n",
       "\n",
       "   model_layers  def_param  def_value  atk_param  atk_value  failure_rate  \\\n",
       "0            34     cutoff   1.000000        eps   0.300000  2.766349e+05   \n",
       "5            34        NaN        NaN        eps   0.123905  1.435355e+06   \n",
       "6            34        NaN        NaN   nb_grads   1.000000  6.608925e+06   \n",
       "8            18        NaN        NaN   nb_grads   1.000000  9.488474e+04   \n",
       "9            34     cutoff   0.224719   max_iter   0.210526  3.184056e+04   \n",
       "\n",
       "   adv_failure_rate  training_time_per_failure  training_time_per_adv_failure  \\\n",
       "0      22947.190553               1.334096e-08                   1.608291e-07   \n",
       "5     147157.749244               2.527946e-09                   2.465721e-08   \n",
       "6       6524.344491               1.244199e-10                   1.260329e-07   \n",
       "8      10296.684193               4.784913e-09                   4.409334e-08   \n",
       "9         73.692387               1.164213e-07                   5.030261e-05   \n",
       "\n",
       "   adv_training_time_per_failure  \n",
       "0                   1.608291e-07  \n",
       "5                   2.465721e-08  \n",
       "6                   1.260329e-07  \n",
       "8                   4.409334e-08  \n",
       "9                   5.030261e-05  \n",
       "\n",
       "[5 rows x 196 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FOLDER = Path(\"output/plots/\")\n",
    "csv_file = FOLDER / \"data.csv\"\n",
    "data = pd.read_csv(csv_file, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_aft(\n",
    "    data,\n",
    "    file,\n",
    "    event_col,\n",
    "    duration_col,\n",
    "    title,\n",
    "    mtype,\n",
    "    xlabel=\"$\\log(\\eta)$ - 95% CI\",\n",
    "    ylabel=\"Covariate\",\n",
    "    replacement_dict={},\n",
    "    **kwargs,\n",
    "):\n",
    "    if mtype == \"weibull\":\n",
    "        aft = WeibullAFTFitter(**kwargs)\n",
    "    elif mtype == \"log_normal\":\n",
    "        aft = LogNormalAFTFitter(**kwargs)\n",
    "    elif mtype == \"log_logistic\":\n",
    "        aft = LogLogisticAFTFitter(**kwargs)\n",
    "    df, test = train_test_split(data, test_size=0.2, random_state=42)\n",
    "    assert (\n",
    "        duration_col in df.columns\n",
    "    ), f\"Column {duration_col} not in dataframe with columns {df.columns}\"\n",
    "    assert (\n",
    "        event_col in df.columns\n",
    "    ), f\"Column {event_col} not in dataframe with columns {df.columns}\"\n",
    "    aft.fit(df, duration_col=duration_col, event_col=event_col)\n",
    "    aft.fit(df, duration_col=duration_col, event_col=event_col)\n",
    "    ax = aft.plot()\n",
    "    ax.set_ylabel(ylabel)\n",
    "    labels = ax.get_yticklabels()\n",
    "    labels = [label.get_text() for label in labels]\n",
    "    for k, v in replacement_dict.items():\n",
    "        labels = [label.replace(k, v) for label in labels]\n",
    "    ax.set_yticklabels(labels)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_title(title)\n",
    "    ax.get_figure().tight_layout()\n",
    "    ax.get_figure().savefig(FOLDER / file)\n",
    "    logger.info(f\"Saved graph to {FOLDER / file}\")\n",
    "    return ax, aft\n",
    "\n",
    "\n",
    "def clean_data_for_aft(\n",
    "    data, kwarg_list, standard_scaling=True, target=\"adv_failure_rate\"\n",
    "):\n",
    "    subset = data.copy()\n",
    "    y = subset[target].copy(deep=True)\n",
    "    cleaned = pd.DataFrame()\n",
    "    if target in kwarg_list:\n",
    "        kwarg_list.remove(target)\n",
    "    for kwarg in kwarg_list:\n",
    "        cleaned = pd.concat([cleaned, subset[kwarg]], axis=1)\n",
    "    cols = cleaned.columns\n",
    "    if standard_scaling is True:\n",
    "        scaler = StandardScaler()\n",
    "        scaler = scaler.fit(cleaned)\n",
    "        cleaned_numeric = pd.DataFrame(scaler.transform(cleaned), columns=cols)\n",
    "    else:\n",
    "        cleaned_numeric = cleaned\n",
    "\n",
    "    cleaned_numeric = pd.DataFrame(subset, columns=cols)\n",
    "    cleaned_numeric.def_value.fillna(0, inplace=True)\n",
    "    # replace 0 with 1e-6\n",
    "    # cleaned_numeric = cleaned_numeric.replace(0, replace_0)\n",
    "    return cleaned_numeric, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'random_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/deckard/env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3652\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3651\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/deckard/env/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/deckard/env/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'random_state'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m      1\u001b[0m kwarg_list \u001b[39m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain_time\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[39m# \"adv_accuracy\",\u001b[39;00m\n\u001b[1;32m     14\u001b[0m ]\n\u001b[0;32m---> 17\u001b[0m cleaned, y \u001b[39m=\u001b[39m clean_data_for_aft(data, kwarg_list, standard_scaling\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     18\u001b[0m cleaned\u001b[39m.\u001b[39mdropna(axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m, how\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39many\u001b[39m\u001b[39m\"\u001b[39m, subset\u001b[39m=\u001b[39mkwarg_list\u001b[39m.\u001b[39mremove(\u001b[39m\"\u001b[39m\u001b[39mdef_value\u001b[39m\u001b[39m\"\u001b[39m), inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     19\u001b[0m cleaned[\u001b[39m\"\u001b[39m\u001b[39madv_failure_rate\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m y\n",
      "Cell \u001b[0;32mIn[3], line 52\u001b[0m, in \u001b[0;36mclean_data_for_aft\u001b[0;34m(data, kwarg_list, standard_scaling, target)\u001b[0m\n\u001b[1;32m     50\u001b[0m     kwarg_list\u001b[39m.\u001b[39mremove(target)\n\u001b[1;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m kwarg \u001b[39min\u001b[39;00m kwarg_list:\n\u001b[0;32m---> 52\u001b[0m     cleaned \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([cleaned, subset[kwarg]], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     53\u001b[0m cols \u001b[39m=\u001b[39m cleaned\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m standard_scaling \u001b[39mis\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/deckard/env/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/deckard/env/lib/python3.8/site-packages/pandas/core/indexes/base.py:3654\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3653\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3654\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3655\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3656\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3657\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'random_state'"
     ]
    }
   ],
   "source": [
    "kwarg_list = [\n",
    "    \"accuracy\",\n",
    "    \"train_time\",\n",
    "    \"atk_value\",\n",
    "    \"def_value\",\n",
    "    \"adv_fit_time\",\n",
    "    \"random_state\",\n",
    "    \"adv_failure_rate\",\n",
    "    \"predict_time\",\n",
    "    # \"adv_fit_time\",\n",
    "    # \"adv_accuracy\",\n",
    "    # \"adv_fit_time_per_sample\",\n",
    "    # \"adv_accuracy\",\n",
    "]\n",
    "\n",
    "\n",
    "cleaned, y = clean_data_for_aft(data, kwarg_list, standard_scaling=True)\n",
    "cleaned.dropna(axis=0, how=\"any\", subset=kwarg_list.remove(\"def_value\"), inplace=True)\n",
    "cleaned[\"adv_failure_rate\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weibull_dict = {\n",
    "    \"Intercept: rho_\": \"$\\\\rho$\",\n",
    "    \"Intercept: lambda_\": \"$\\lambda$\",\n",
    "    \"random_state: lambda_\": \"Random State\",\n",
    "    \"def_value: lambda_\": \"Defence Strength\",\n",
    "    \"atk_value: lambda_\": \"Attack Strength\",\n",
    "    \"train_time: lambda_\": \"Training Time\",\n",
    "    \"predict_time: lambda_\": \"Inference Time\",\n",
    "    \"accuracy: lambda_\": \"Ben. Accuracy\",\n",
    "}\n",
    "\n",
    "weibull_graph, wft = plot_aft(\n",
    "    cleaned,\n",
    "    \"weibull_aft.pdf\",\n",
    "    \"adv_failure_rate\",\n",
    "    \"adv_fit_time\",\n",
    "    \"Weibull AFT Model\",\n",
    "    \"weibull\",\n",
    "    replacement_dict=weibull_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_normal_dict = {\n",
    "    \"Intercept: sigma_\": \"$\\sigma$\",\n",
    "    \"Intercept: mu_\": \"$\\mu$\",\n",
    "    \"random_state: mu_\": \"Random State\",\n",
    "    \"def_value: mu_\": \"Defence Strength\",\n",
    "    \"atk_value: mu_\": \"Attack Strength\",\n",
    "    \"train_time: mu_\": \"Training Time\",\n",
    "    \"predict_time: mu_\": \"Inference Time\",\n",
    "    \"accuracy: mu_\": \"Ben. Accuracy\",\n",
    "    \"adv_fit_time: mu_\": \"Adv. Fit Time\",\n",
    "}\n",
    "\n",
    "log_normal_graph, lnt = plot_aft(\n",
    "    cleaned,\n",
    "    \"log_normal_aft.pdf\",\n",
    "    \"adv_failure_rate\",\n",
    "    \"adv_fit_time\",\n",
    "    \"Log Normal AFT Model\",\n",
    "    \"log_normal\",\n",
    "    replacement_dict=log_normal_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 14\u001b[0m\n\u001b[1;32m      1\u001b[0m log_logistic_dict \u001b[39m=\u001b[39m {\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mIntercept: beta_\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39mbeta$\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mIntercept: alpha_\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m$\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39malpha$\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madv_fit_time: alpha_\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mAdv. Fit Time\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m log_logistic_graph, llt \u001b[39m=\u001b[39m plot_aft(\n\u001b[0;32m---> 14\u001b[0m     cleaned,\n\u001b[1;32m     15\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlog_logistic_aft.pdf\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madv_failure_rate\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madv_fit_time\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLog Logistic AFT Model\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mlog_logistic\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     replacement_dict\u001b[39m=\u001b[39mlog_logistic_dict,\n\u001b[1;32m     21\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cleaned' is not defined"
     ]
    }
   ],
   "source": [
    "log_logistic_dict = {\n",
    "    \"Intercept: beta_\": \"$\\\\beta$\",\n",
    "    \"Intercept: alpha_\": \"$\\\\alpha$\",\n",
    "    \"random_state: alpha_\": \"Random State\",\n",
    "    \"def_value: alpha_\": \"Defence Strength\",\n",
    "    \"atk_value: alpha_\": \"Attack Strength\",\n",
    "    \"train_time: alpha_\": \"Training Time\",\n",
    "    \"predict_time: alpha_\": \"Inference Time\",\n",
    "    \"accuracy: alpha_\": \"Ben. Accuracy\",\n",
    "    \"adv_fit_time: alpha_\": \"Adv. Fit Time\",\n",
    "}\n",
    "\n",
    "log_logistic_graph, llt = plot_aft(\n",
    "    cleaned,\n",
    "    \"log_logistic_aft.pdf\",\n",
    "    \"adv_failure_rate\",\n",
    "    \"adv_fit_time\",\n",
    "    \"Log Logistic AFT Model\",\n",
    "    \"log_logistic\",\n",
    "    replacement_dict=log_logistic_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m aft_dict \u001b[39m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mWeibull\u001b[39m\u001b[39m\"\u001b[39m: wft,\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLogNormal\u001b[39m\u001b[39m\"\u001b[39m: lnt,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mLogLogistic\u001b[39m\u001b[39m\"\u001b[39m: llt,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m aft_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n\u001b[1;32m      7\u001b[0m aft_data\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mname \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mModel\u001b[39m\u001b[39m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'wft' is not defined"
     ]
    }
   ],
   "source": [
    "aft_dict = {\n",
    "    \"Weibull\": wft,\n",
    "    \"LogNormal\": lnt,\n",
    "    \"LogLogistic\": llt,\n",
    "}\n",
    "aft_data = pd.DataFrame()\n",
    "aft_data.index.name = \"Model\"\n",
    "aft_data.index = aft_dict.keys()\n",
    "aft_data[\"AIC\"] = [x.AIC_ for x in aft_dict.values()]\n",
    "aft_data[\"LogLikelihood\"] = [x.log_likelihood_ for x in aft_dict.values()]\n",
    "aft_data[\"Concordance Score\"] = [x.concordance_index_ for x in aft_dict.values()]\n",
    "aft_data[\"BIC\"] = [x.BIC_ for x in aft_dict.values()]\n",
    "aft_data = aft_data.round(2)\n",
    "aft_data.to_csv(FOLDER / \"aft_comparison.csv\")\n",
    "logger.info(f\"Saved AFT comparison to {FOLDER / 'aft_comparison.csv'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
